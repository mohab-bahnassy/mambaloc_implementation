#!/usr/bin/env python3
"""
CSI Teacher Ablation Study

This experiment tests alternative teacher architectures:
1. CSI-Transformer Teacher â†’ CSI-Mamba Student (same modality, different architecture)
2. CSI-Mamba Teacher â†’ CSI-Mamba Student (same modality, same architecture)
3. Baseline: CSI-Mamba only (no teacher)
4. Original: UWB-Transformer Teacher â†’ CSI-Mamba Student (for comparison)

Reuses functions from truly_fair_comparison.py where possible.
"""

import os
import sys
import json
import numpy as np
from datetime import datetime
from typing import Dict, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data

# Import reusable components from truly_fair_comparison.py
sys.path.append('.')
from truly_fair_comparison import (
    # Constants
    NUM_GAUSSIANS, COORD_MIN, COORD_MAX_X, COORD_MAX_Y,
    
    # Model components
    ContinuousCoordinateHead,
    ContinuousUWBTransformerTeacher,
    ContinuousCSIRegressionModel,
    
    # Training functions
    train_continuous_probability_distilled,
    train_gmm_baseline,
    
    # Data loading
    create_truly_fair_dataloaders,
    
    # Evaluation (available function)
    evaluate_baseline_vs_continuous_probability
)

# Import required modules for new teacher models
from modules.csi_head import CSIRegressionModel

# Additional imports for evaluation and plotting
import matplotlib.pyplot as plt
from sklearn.metrics import r2_score


def evaluate_model_performance(model, test_loader, device, model_name, target_scaler=None):
    """
    Evaluate model performance using standard metrics in REAL coordinate space.
    Returns dictionary with MAE, Median AE, and RÂ² scores.
    FIXED: Denormalizes coordinates back to real space before calculating errors.
    """
    print(f"ğŸ“Š Evaluating {model_name}...")
    
    model.eval()
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(test_loader):
            try:
                # Handle different batch formats (same as truly_fair_comparison.py)
                if len(batch_data) == 4:  # UWB + CSI batch (distilled data)
                    uwb_data, uwb_targets, csi_data, csi_targets = batch_data
                    data = csi_data.float().to(device)
                    targets = csi_targets.float().to(device)
                elif len(batch_data) == 2:  # CSI only batch (baseline data)
                    data, targets = batch_data
                    data = data.float().to(device)
                    targets = targets.float().to(device)
                else:
                    print(f"âš ï¸ Unexpected batch format: {len(batch_data)} elements")
                    continue
                
                # Handle target shape
                if targets.dim() > 2:
                    targets = targets[:, -1, :]  # Take last timestep
                if targets.shape[-1] != 2:
                    targets = targets[:, :2]  # Take x, y only
                
                # Get model predictions
                output = model(data, targets=targets)
                if hasattr(output, 'coordinates'):
                    predictions = output.coordinates
                elif isinstance(output, dict) and 'coordinates' in output:
                    predictions = output['coordinates']
                elif hasattr(output, 'predictions'):
                    predictions = output.predictions
                else:
                    predictions = output  # Assume raw predictions
                
                # Handle prediction shape
                if predictions.dim() > 2:
                    predictions = predictions[:, -1, :]  # Take last timestep
                if predictions.shape[-1] != 2:
                    predictions = predictions[:, :2]  # Take x, y only
                
                all_predictions.append(predictions.cpu().numpy())
                all_targets.append(targets.cpu().numpy())
                
                # Use ALL batches for evaluation (removed batch limit)
                    
            except Exception as e:
                print(f"âš ï¸ Error in batch {batch_idx}: {e}")
                continue
    
    if len(all_predictions) == 0:
        print(f"âš ï¸ No valid predictions for {model_name}")
        return {'mae': 999.0, 'median_ae': 999.0, 'r2': -999.0, 'errors': np.array([999.0])}
    
    # Concatenate all predictions and targets
    predictions = np.concatenate(all_predictions, axis=0)
    targets = np.concatenate(all_targets, axis=0)
    
    print(f"   ğŸ“Š Before denormalization:")
    print(f"      Predictions range: [{predictions.min():.3f}, {predictions.max():.3f}]")
    print(f"      Targets range: [{targets.min():.3f}, {targets.max():.3f}]")
    
    # CRITICAL FIX: Denormalize coordinates back to real space (same as truly_fair_comparison.py)
    if target_scaler is not None:
        predictions_real = target_scaler.inverse_transform(predictions)
        targets_real = target_scaler.inverse_transform(targets)
        
        print(f"   ğŸ“ After denormalization (REAL COORDINATES):")
        print(f"      Predictions range: [{predictions_real.min():.3f}, {predictions_real.max():.3f}] meters")
        print(f"      Targets range: [{targets_real.min():.3f}, {targets_real.max():.3f}] meters")
    else:
        print(f"   âš ï¸ WARNING: No target scaler provided - using normalized coordinates")
        predictions_real = predictions
        targets_real = targets
    
    # Calculate metrics in REAL coordinate space
    errors = np.sqrt(np.sum((predictions_real - targets_real) ** 2, axis=1))  # Euclidean distance
    mae = np.mean(errors)
    median_ae = np.median(errors)
    
    # RÂ² calculation in real space
    ss_res = np.sum((targets_real - predictions_real) ** 2)
    ss_tot = np.sum((targets_real - np.mean(targets_real, axis=0)) ** 2)
    r2 = 1 - (ss_res / (ss_tot + 1e-8))
    
    coordinate_space = "real_meters" if target_scaler is not None else "normalized"
    print(f"   âœ… {model_name} ({coordinate_space}): MAE={mae:.4f}, Median AE={median_ae:.4f}, RÂ²={r2:.4f}")
    
    return {
        'mae': float(mae),
        'median_ae': float(median_ae),
        'r2': float(r2),
        'num_samples': len(predictions),
        'errors': errors,  # Include raw errors for plotting (in real space)
        'coordinate_space': coordinate_space
    }


def plot_error_cdf_comparison(error_data_dict, filename):
    """
    Plot CDF comparison of error distributions for multiple models.
    
    Args:
        error_data_dict: Dict of {model_name: error_array}
        filename: Output filename for the plot
    """
    print(f"ğŸ“ˆ Creating CDF comparison plot: {filename}")
    
    plt.figure(figsize=(12, 8))
    
    colors = ['blue', 'red', 'green', 'orange', 'purple']
    linestyles = ['-', '--', '-.', ':', '-']
    
    for i, (model_name, errors) in enumerate(error_data_dict.items()):
        # Sort errors for CDF
        sorted_errors = np.sort(errors)
        # Calculate CDF values
        y = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)
        
        plt.plot(sorted_errors, y, 
                label=f'{model_name} (Median: {np.median(errors):.3f}m)',
                color=colors[i % len(colors)],
                linestyle=linestyles[i % len(linestyles)],
                linewidth=2)
    
    plt.xlabel('Localization Error (meters) - REAL COORDINATE SPACE', fontsize=12, fontweight='bold')
    plt.ylabel('Cumulative Probability', fontsize=12, fontweight='bold')
    plt.title('CDF Comparison: CSI Teacher Ablation Study\n(Lower curves = better performance, REAL coordinate errors)', 
              fontsize=14, fontweight='bold')
    plt.legend(fontsize=10, loc='best')
    plt.grid(True, alpha=0.3)
    plt.xlim(0, min(4.0, max([np.percentile(errors, 95) for errors in error_data_dict.values()])))
    plt.ylim([0, 1])
    
    # Add text box with summary statistics
    textstr = '\n'.join([
        f"ğŸ“Š CSI Teacher Ablation (REAL meters):",
        f"Gaussian Mixture: {NUM_GAUSSIANS} components",
        f"Room coverage: X=[0,{COORD_MAX_X}]m, Y=[0,{COORD_MAX_Y}]m"
    ])
    
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
    plt.text(0.98, 0.02, textstr, fontsize=9,
             verticalalignment='bottom', horizontalalignment='right', bbox=props)
    
    plt.tight_layout()
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"   âœ… CDF plot saved: {filename}")


class CSITransformerTeacher(nn.Module):
    """
    CSI Transformer Teacher that processes CSI data instead of UWB.
    Uses Transformer architecture but with CSI input modality.
    """
    
    def __init__(self, input_features=540, d_model=80, n_layers=2, n_heads=4, device="cuda"):
        super().__init__()
        self.input_features = input_features  # CSI features (actual dimensions from data)
        self.d_model = d_model
        self.device = device
        
        # Input projection for CSI data with better initialization
        self.input_projection = nn.Linear(input_features, d_model)
        # Better initialization for CSI data
        nn.init.xavier_uniform_(self.input_projection.weight)
        nn.init.zeros_(self.input_projection.bias)
        
        # Add positional encoding for sequence modeling
        self.pos_encoding = nn.Parameter(torch.randn(1, 1000, d_model) * 0.1)  # Support up to 1000 timesteps
        
        # Transformer layers with improved architecture
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=n_heads,
            dim_feedforward=d_model * 4,  # Increased capacity (was d_model * 2)
            dropout=0.1,
            activation='gelu',  # Better activation for CSI data
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)
        
        # Add layer normalization for better training stability
        self.layer_norm = nn.LayerNorm(d_model)
        
        # Continuous coordinate head (same as UWB teacher)
        self.coordinate_head = ContinuousCoordinateHead(d_model)
        
    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        Forward pass for CSI Transformer teacher.
        
        Args:
            x: [batch, seq_len, input_features] CSI data
            
        Returns:
            Dict with 'logits', 'probabilities', 'coordinates', etc.
        """
        batch_size, seq_len, _ = x.shape
        
        # Project CSI data to model dimension
        x = self.input_projection(x)  # [batch, seq_len, d_model]
        
        # Add positional encoding
        seq_len = x.size(1)
        if seq_len <= self.pos_encoding.size(1):
            x = x + self.pos_encoding[:, :seq_len, :]
        else:
            # Handle longer sequences by repeating positional encoding
            pos_enc = self.pos_encoding.repeat(1, (seq_len // self.pos_encoding.size(1)) + 1, 1)
            x = x + pos_enc[:, :seq_len, :]
        
        # Apply transformer
        features = self.transformer(x)  # [batch, seq_len, d_model]
        
        # Apply layer normalization for better stability
        features = self.layer_norm(features)
        
        # Get continuous coordinate distribution
        output = self.coordinate_head(features)
        output['features'] = features  # For potential feature-level distillation
        
        return output


class CSIMambaTeacher(nn.Module):
    """
    CSI Mamba Teacher that processes CSI data using Mamba architecture.
    Same architecture as student but acts as teacher (trained first).
    """
    
    def __init__(self, csi_config: dict, device: str = "cuda"):
        super().__init__()
        self.config = csi_config
        self.device = device
        
        # Create CSI Mamba backbone (same as student architecture)
        self.csi_backbone = CSIRegressionModel(csi_config, device=device).to(device)
        
        # Get d_model from config
        d_model = csi_config["UWBMixerModel"]["input"]["d_model"]
        
        # Continuous coordinate head (same as other teachers)
        self.coordinate_head = ContinuousCoordinateHead(d_model).to(device)
        
    def forward(self, x: torch.Tensor, targets: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:
        """
        Forward pass for CSI Mamba teacher.
        
        Args:
            x: [batch, seq_len, input_features] CSI data
            targets: Optional targets for backbone
            
        Returns:
            Dict with 'logits', 'probabilities', 'coordinates', etc.
        """
        # Get features from Mamba backbone
        backbone_output = self.csi_backbone(x, targets=targets)
        
        # Extract hidden states
        if backbone_output.last_hidden_state is not None:
            features = backbone_output.last_hidden_state  # [batch, seq_len, d_model]
        else:
            raise ValueError("No hidden states from CSI Mamba backbone")
        
        # Get continuous coordinate distribution
        output = self.coordinate_head(features)
        output['features'] = features  # For potential feature-level distillation
        
        return output


class EnhancedFeatureAlignmentModule(nn.Module):
    """
    Enhanced feature alignment module with better normalization, regularization, and attention.
    Specifically designed to handle CSI-Transformer â†’ CSI-Mamba architectural differences.
    """

    def __init__(self, teacher_dim: int, student_dim: int, alignment_dim: int = 128):
        super().__init__()

        # Enhanced feature projectors with better normalization
        self.teacher_proj = nn.Sequential(
            nn.Linear(teacher_dim, alignment_dim),
            nn.LayerNorm(alignment_dim),
            nn.GELU(),  # Better activation for features
            nn.Dropout(0.05),  # Reduced dropout
            nn.Linear(alignment_dim, alignment_dim),
            nn.LayerNorm(alignment_dim),
            nn.GELU(),
            nn.Dropout(0.05)
        )

        self.student_proj = nn.Sequential(
            nn.Linear(student_dim, alignment_dim),
            nn.LayerNorm(alignment_dim),
            nn.GELU(),
            nn.Dropout(0.05),
            nn.Linear(alignment_dim, alignment_dim),
            nn.LayerNorm(alignment_dim),
            nn.GELU(),
            nn.Dropout(0.05)
        )

        # Multi-head cross-attention with improved configuration
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=alignment_dim,
            num_heads=16,  # More heads for better feature selection
            dropout=0.05,  # Reduced dropout
            batch_first=True,
            kdim=alignment_dim,
            vdim=alignment_dim
        )

        # Enhanced feature adaptation for Mamba
        self.mamba_adapter = nn.Sequential(
            nn.Linear(alignment_dim, alignment_dim),
            nn.LayerNorm(alignment_dim),
            nn.Tanh(),
            nn.Dropout(0.05),
            nn.Linear(alignment_dim, student_dim),
            nn.LayerNorm(student_dim),
            nn.Tanh(),  # Double tanh for better Mamba compatibility
            nn.Linear(student_dim, student_dim)
        )

        # Feature normalization for better alignment
        self.teacher_feature_norm = nn.LayerNorm(teacher_dim)
        self.student_feature_norm = nn.LayerNorm(student_dim)

        # Enhanced loss functions
        self.mse_loss = nn.MSELoss()
        self.cosine_loss = nn.CosineEmbeddingLoss()
        self.smooth_l1_loss = nn.SmoothL1Loss()

        # Attention-based feature selector
        self.attention_gate = nn.Sequential(
            nn.Linear(alignment_dim, alignment_dim // 2),
            nn.ReLU(),
            nn.Linear(alignment_dim // 2, alignment_dim),
            nn.Sigmoid()
        )

    def forward(self, teacher_features: torch.Tensor, student_features: torch.Tensor):
        """
        Enhanced feature alignment with multiple loss components and better attention.
        """
        batch_size = teacher_features.size(0)

        # Normalize input features with appropriate dimensions
        teacher_features = self.teacher_feature_norm(teacher_features)
        student_features = self.student_feature_norm(student_features)

        # Project to common alignment space
        teacher_aligned = self.teacher_proj(teacher_features)
        student_aligned = self.student_proj(student_features)

        # Add sequence dimension for attention
        teacher_seq = teacher_aligned.unsqueeze(1)  # [batch, 1, alignment_dim]
        student_seq = student_aligned.unsqueeze(1)  # [batch, 1, alignment_dim]

        # Enhanced cross-attention with residual connection
        attended_teacher, attention_weights = self.cross_attention(
            query=student_seq,
            key=teacher_seq,
            value=teacher_seq
        )
        attended_teacher = attended_teacher.squeeze(1)  # [batch, alignment_dim]

        # Attention-based feature gating
        attention_gates = self.attention_gate(attended_teacher)  # [batch, alignment_dim]
        attended_teacher = attended_teacher * attention_gates  # Selective feature transfer

        # Adapt features for Mamba compatibility
        adapted_features = self.mamba_adapter(attended_teacher)

        # Compute enhanced alignment losses
        direct_alignment_loss = self.mse_loss(teacher_aligned, student_aligned.detach())

        # Cosine similarity for semantic alignment
        cosine_targets = torch.ones(batch_size, device=teacher_features.device)
        cosine_alignment_loss = self.cosine_loss(
            teacher_aligned, student_aligned.detach(), cosine_targets
        )

        # Attention-based alignment
        attention_alignment_loss = self.mse_loss(attended_teacher, student_aligned.detach())

        # Adaptation loss with smooth L1 for robustness
        adaptation_loss = self.smooth_l1_loss(adapted_features, student_features.detach())

        # Regularization loss to prevent overfitting
        teacher_reg_loss = torch.mean(torch.norm(teacher_aligned, p=2, dim=1))
        student_reg_loss = torch.mean(torch.norm(student_aligned, p=2, dim=1))

        # Weighted combination with improved weights
        total_alignment_loss = (
            0.3 * direct_alignment_loss +
            0.2 * cosine_alignment_loss +
            0.3 * attention_alignment_loss +
            0.15 * adaptation_loss +
            0.025 * (teacher_reg_loss + student_reg_loss)
        )

        return {
            'total_loss': total_alignment_loss,
            'direct_loss': direct_alignment_loss,
            'cosine_loss': cosine_alignment_loss,
            'attention_loss': attention_alignment_loss,
            'adaptation_loss': adaptation_loss,
            'teacher_aligned': teacher_aligned,
            'student_aligned': student_aligned,
            'adapted_features': adapted_features,
            'attention_weights': attention_weights,
            'attention_gates': attention_gates
        }


class EnhancedCrossArchitectureTransfer(nn.Module):
    """
    Enhanced cross-architecture transfer module with improved feature alignment,
    curriculum learning, and better regularization for CSI-Transformer â†’ CSI-Mamba.
    """

    def __init__(self, teacher_dim: int, student_dim: int):
        super().__init__()

        # Enhanced feature alignment
        self.feature_aligner = EnhancedFeatureAlignmentModule(
            teacher_dim=teacher_dim,
            student_dim=student_dim,
            alignment_dim=128
        )

        # Curriculum learning controller
        self.curriculum_controller = nn.Sequential(
            nn.Linear(3, 64),  # [epoch_progress, alignment_loss, temperature]
            nn.LayerNorm(64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.LayerNorm(32),
            nn.ReLU(),
            nn.Linear(32, 5)  # [direct_w, cosine_w, attention_w, adaptation_w, reg_w]
        )

        # Feature-level curriculum learning
        self.feature_curriculum = nn.Sequential(
            nn.Linear(2, 32),  # [epoch_progress, feature_similarity]
            nn.ReLU(),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),  # Feature alignment strength
            nn.Sigmoid()
        )

        # Temperature-based loss weighting
        self.temperature_controller = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Linear(16, 4),  # [kl_weight, feature_weight, reg_weight, temperature_scale]
        )

    def compute_enhanced_weights(self, epoch: int, total_epochs: int,
                                alignment_loss: float, temperature: float):
        """Compute curriculum-based weights for different loss components."""
        epoch_progress = epoch / (total_epochs - 1)  # 0 to 1
        normalized_loss = min(alignment_loss / 1.0, 5.0)  # Cap at 5

        # Curriculum controller inputs - ensure correct device
        device = next(self.curriculum_controller.parameters()).device
        inputs = torch.tensor([[epoch_progress, normalized_loss, temperature / 30.0]],
                             dtype=torch.float32, device=device)
        weights = torch.softmax(self.curriculum_controller(inputs), dim=-1)

        return weights[0].detach().cpu().numpy()

    def compute_feature_curriculum(self, epoch: int, total_epochs: int,
                                  teacher_features: torch.Tensor, student_features: torch.Tensor):
        """Compute feature-level curriculum learning strength."""
        epoch_progress = epoch / (total_epochs - 1)

        # Compute feature similarity as a scalar
        teacher_feat_mean = teacher_features.mean(dim=0)  # [d_model]
        student_feat_mean = student_features.mean(dim=0)  # [d_model]
        
        cosine_sim = torch.cosine_similarity(
            teacher_feat_mean.unsqueeze(0),
            student_feat_mean.unsqueeze(0),
            dim=1
        )

        # Ensure inputs are on the same device as the model
        device = next(self.feature_curriculum.parameters()).device
        inputs = torch.tensor([[epoch_progress, cosine_sim.item()]], 
                             dtype=torch.float32, device=device)
        curriculum_strength = self.feature_curriculum(inputs)

        return curriculum_strength.item()

    def forward(self, teacher_features: torch.Tensor, student_features: torch.Tensor):
        """Enhanced cross-architecture feature transfer with curriculum learning."""
        # Get alignment results
        alignment_results = self.feature_aligner(teacher_features, student_features)

        return alignment_results


def train_csi_teacher_distilled(
    teacher_model: nn.Module,
    teacher_type: str,  # "transformer" or "mamba"
    csi_config: dict,
    data_loaders: dict,
    device: str = "cuda",
    epochs: int = 15,
    temperature: float = 15.0,
    alpha: float = 0.2,
    beta: float = 0.8,
    step_size: float = 0.01,
    teacher_lr: float = 1e-3,
    student_lr: float = 5e-4
) -> ContinuousCSIRegressionModel:
    """
    Train CSI teacher â†’ CSI student knowledge distillation.
    
    Args:
        teacher_model: CSI teacher (Transformer or Mamba)
        teacher_type: "transformer" or "mamba" 
        csi_config: Student model configuration
        data_loaders: Training/validation data
        Other args: Same as UWB distillation
        
    Returns:
        Trained CSI student model
    """
    print(f"ğŸ“ Training CSI-{teacher_type.upper()} â†’ CSI-MAMBA distillation...")
    print(f"   - Teacher: CSI-{teacher_type.upper()} â†’ Continuous probabilities")
    print(f"   - Student: CSI-MAMBA â†’ Continuous probabilities") 
    print(f"   - T={temperature}, Î±_start={alpha}, Î²_start={beta}")
    print(f"   - Same modality (CSI), different architecture")
    
    # Scheduling parameters (same as UWB distillation)
    alpha_min, alpha_max = 0.1, 0.6
    beta_min, beta_max = 0.4, 0.9
    
    current_alpha = max(alpha_min, min(alpha_max, alpha))
    current_beta = max(beta_min, min(beta_max, beta))
    
    recent_distill_losses = []
    recent_task_losses = []
    performance_window = 3
    
    # 1. Train CSI teacher on CSI data
    print(f"   ğŸ¯ Training CSI-{teacher_type.upper()} teacher...")
    for param in teacher_model.parameters():
        param.requires_grad = True
    teacher_model.train()
    
    teacher_epochs = 30 if teacher_type == "transformer" else 25  # More training for Transformer (+10 epochs each)
    # Use different learning rates based on teacher type
    adaptive_lr = teacher_lr * 1.5 if teacher_type == "transformer" else teacher_lr  # Higher LR for Transformer
    teacher_optimizer = torch.optim.AdamW(teacher_model.parameters(), lr=adaptive_lr, weight_decay=1e-4)
    print(f"   ğŸ“Š CSI-{teacher_type.upper()} Teacher LR: {adaptive_lr:.0e} ({'adaptive' if teacher_type == 'transformer' else 'standard'})")
    teacher_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(teacher_optimizer, T_max=teacher_epochs)
    
    # Teacher training (15 epochs)
    for epoch in range(teacher_epochs):
        teacher_model.train()
        teacher_losses = []
        
        for batch_idx, (uwb_data, uwb_targets, csi_data, csi_targets) in enumerate(data_loaders['distilled']['train']):
            # Use CSI data for teacher (not UWB!)
            csi_data = csi_data.float().to(device)
            csi_targets = csi_targets.float().to(device)
            
            teacher_optimizer.zero_grad()
            
            # Forward pass through CSI teacher
            if teacher_type == "mamba":
                # CSI Mamba teacher needs targets parameter
                teacher_output = teacher_model(csi_data, targets=csi_targets)
            else:
                # CSI Transformer teacher doesn't need targets
                teacher_output = teacher_model(csi_data)
            
            # Extract coordinates for teacher training loss
            if hasattr(teacher_output, 'coordinates'):
                teacher_coordinates = teacher_output.coordinates
            elif isinstance(teacher_output, dict) and 'coordinates' in teacher_output:
                teacher_coordinates = teacher_output['coordinates']
            else:
                teacher_coordinates = teacher_output
            
            # Teacher learns CSI â†’ coordinates mapping
            teacher_loss = nn.MSELoss()(teacher_coordinates, csi_targets)
            teacher_loss.backward()
            torch.nn.utils.clip_grad_norm_(teacher_model.parameters(), max_norm=1.0)
            teacher_optimizer.step()
            
            teacher_losses.append(teacher_loss.item())
            
            if batch_idx >= 30:  # More batches per epoch (match truly_fair_comparison.py)
                break
        
        teacher_scheduler.step()
        if epoch % 3 == 0:
            avg_loss = np.mean(teacher_losses)
            print(f"   CSI-{teacher_type.upper()} Teacher Epoch {epoch}: Loss={avg_loss:.6f}")
            # Monitor if teacher is learning effectively
            if epoch == 0:
                initial_loss = avg_loss
            elif epoch >= 12:
                improvement = ((initial_loss - avg_loss) / initial_loss) * 100
                if improvement < 10:
                    print(f"   âš ï¸ WARNING: CSI-{teacher_type.upper()} teacher showing limited improvement ({improvement:.1f}%)")
    
    # 2. Freeze teacher for distillation
    for param in teacher_model.parameters():
        param.requires_grad = False
    teacher_model.eval()
    print(f"   âœ… CSI-{teacher_type.upper()} teacher training completed and frozen")
    
    # 3. Create and train student model with advanced cross-architecture transfer
    student_model = ContinuousCSIRegressionModel(csi_config, device=device).to(device)
    print(f"ğŸ–¥ï¸ CSI Student Model moved to {device}")

    # Create enhanced cross-architecture transfer module for CSI-Transformer â†’ CSI-Mamba
    cross_arch_transfer = None
    if teacher_type == "transformer":
        d_model = csi_config["UWBMixerModel"]["input"]["d_model"]
        cross_arch_transfer = EnhancedCrossArchitectureTransfer(
            teacher_dim=d_model,
            student_dim=d_model
        ).to(device)
        print(f"ğŸ”— Enhanced cross-architecture transfer module created for Transformer â†’ Mamba")
        print(f"   ğŸ§  Features: Curriculum learning + Multi-loss alignment + Feature gating + Attention mechanisms")

    student_epochs = 30  # Increased by 10 epochs for better convergence
    student_optimizer = torch.optim.AdamW(student_model.parameters(), lr=student_lr, weight_decay=1e-4)
    student_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(student_optimizer, T_max=student_epochs)
    
    kl_loss = nn.KLDivLoss(reduction='batchmean')
    mse_loss = nn.MSELoss()
    
    print(f"   ğŸ“Š Initial: Î±={current_alpha:.3f}, Î²={current_beta:.3f}")
    if cross_arch_transfer is not None:
        print(f"   ğŸ”— Cross-architecture transfer: ENABLED")
        print(f"   ğŸ“ˆ Enhanced distillation: Logit-level + Feature-level transfer")
    else:
        print(f"   ğŸ”— Cross-architecture transfer: DISABLED (same architecture)")
    
    # 4. Advanced distillation training loop (student: 20 epochs)
    for epoch in range(student_epochs):
        student_model.train()
        if cross_arch_transfer is not None:
            cross_arch_transfer.train()
        epoch_losses = {'total': [], 'kl_distill': [], 'task': [], 'feature_align': []}

        # Enhanced progressive temperature with curriculum learning
        current_temperature = temperature
        if teacher_type == "transformer":
            # Curriculum-based temperature scheduling
            progress = epoch / (student_epochs - 1)
            # Start high, gradually decrease for better convergence
            current_temperature = temperature * (2.0 + progress * 0.5)  # 2.0 â†’ 2.5
        
        for batch_idx, (uwb_data, uwb_targets, csi_data, csi_targets) in enumerate(data_loaders['distilled']['train']):
            # Both teacher and student use CSI data
            csi_data = csi_data.float().to(device)
            csi_targets = csi_targets.float().to(device)
            
            student_optimizer.zero_grad()
            
            # Get teacher probability distributions from CSI
            with torch.no_grad():
                if teacher_type == "mamba":
                    teacher_output = teacher_model(csi_data, targets=csi_targets)
                else:
                    teacher_output = teacher_model(csi_data)
                
                # Extract logits and features from teacher
                if hasattr(teacher_output, 'logits'):
                    teacher_logits = teacher_output.logits
                    teacher_features = teacher_output.features if hasattr(teacher_output, 'features') else None
                elif isinstance(teacher_output, dict) and 'logits' in teacher_output:
                    teacher_logits = teacher_output['logits']
                    teacher_features = teacher_output.get('features', None)
                else:
                    raise ValueError(f"CSI {teacher_type} teacher must provide logits for distillation")
                
                # Apply temperature scaling to teacher logits
                teacher_soft_logits = teacher_logits / current_temperature
                teacher_soft_probs = F.softmax(teacher_soft_logits, dim=-1)
            
            # Get student probability distributions from CSI
            student_output = student_model(csi_data, targets=csi_targets)
            student_logits = student_output.logits
            student_coordinates = student_output.coordinates
            student_features = student_output.features if hasattr(student_output, 'features') else None
            
            # Apply temperature scaling to student logits
            student_soft_logits = student_logits / current_temperature
            student_log_probs = F.log_softmax(student_soft_logits, dim=-1)
            
            # Compute KL divergence loss (knowledge distillation)
            kl_distill_loss = kl_loss(student_log_probs, teacher_soft_probs) * (current_temperature ** 2)
            
            # Task loss (regression on continuous coordinates)
            task_loss = mse_loss(student_coordinates, csi_targets)
            
            # Enhanced feature alignment loss for cross-architecture transfer
            feature_align_loss = 0.0
            if (cross_arch_transfer is not None and
                teacher_features is not None and
                student_features is not None):

                # Take last timestep features for alignment
                teacher_feat_last = teacher_features[:, -1, :]  # [batch, d_model]
                student_feat_last = student_features[:, -1, :]  # [batch, d_model]

                # Enhanced cross-architecture transfer
                transfer_result = cross_arch_transfer(teacher_feat_last, student_feat_last)

                # Curriculum-based feature alignment strength
                curriculum_strength = cross_arch_transfer.compute_feature_curriculum(
                    epoch, student_epochs, teacher_feat_last, student_feat_last
                )

                # Dynamic loss weighting based on curriculum
                weights = cross_arch_transfer.compute_enhanced_weights(
                    epoch, student_epochs, transfer_result['total_loss'].item(), current_temperature
                )

                # Weighted feature alignment loss
                feature_align_loss = curriculum_strength * transfer_result['total_loss']
                epoch_losses['feature_align'].append(feature_align_loss.item())

            # Enhanced combined loss with curriculum-based feature alignment
            total_loss = current_alpha * kl_distill_loss + current_beta * task_loss
            if feature_align_loss > 0:
                # Dynamic feature alignment weight with curriculum learning
                if teacher_type == "transformer":
                    # Curriculum-based weight that adapts to feature similarity
                    progress = epoch / (student_epochs - 1)
                    base_gamma = 0.3 * (1 - progress) + 0.05 * progress  # 0.3 â†’ 0.05
                    # Increase weight if features are dissimilar
                    if teacher_features is not None and student_features is not None:
                        # Take last timestep and compute mean across batch
                        teacher_feat_mean = teacher_features[:, -1, :].mean(dim=0)  # [d_model]
                        student_feat_mean = student_features[:, -1, :].mean(dim=0)  # [d_model]
                        
                        # Compute cosine similarity as a scalar
                        feat_similarity = torch.cosine_similarity(
                            teacher_feat_mean.unsqueeze(0),
                            student_feat_mean.unsqueeze(0),
                            dim=1
                        ).item()
                        similarity_boost = max(0, (1 - feat_similarity)) * 0.2
                        gamma = base_gamma + similarity_boost
                    else:
                        gamma = base_gamma
                else:
                    gamma = 0.1  # Fixed weight for same architecture

                total_loss = total_loss + gamma * feature_align_loss
            
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)
            if cross_arch_transfer is not None:
                torch.nn.utils.clip_grad_norm_(cross_arch_transfer.parameters(), max_norm=1.0)
            student_optimizer.step()
            
            epoch_losses['total'].append(total_loss.item())
            epoch_losses['kl_distill'].append(kl_distill_loss.item())
            epoch_losses['task'].append(task_loss.item())
            
            if batch_idx >= 25:  # Match truly_fair_comparison.py
                break
        
        # Record losses for adaptive scheduling (same logic as UWB version)
        recent_distill_losses.append(np.mean(epoch_losses['kl_distill']))
        recent_task_losses.append(np.mean(epoch_losses['task']))
        
        if len(recent_distill_losses) > performance_window:
            recent_distill_losses.pop(0)
            recent_task_losses.pop(0)
        
        # Adaptive scheduling
        if len(recent_distill_losses) >= performance_window:
            distill_trend = recent_distill_losses[-1] - recent_distill_losses[0]
            task_trend = recent_task_losses[-1] - recent_task_losses[0]
            
            alpha_change = 0
            beta_change = 0
            
            if distill_trend > step_size:
                alpha_change = +step_size
            elif distill_trend < -step_size:
                alpha_change = -step_size
                
            if task_trend > step_size:
                beta_change = +step_size
            elif task_trend < -step_size:
                beta_change = -step_size
            
            current_alpha = max(alpha_min, min(alpha_max, current_alpha + alpha_change))
            current_beta = max(beta_min, min(beta_max, current_beta + beta_change))
            
            # Normalization (with safety check for the bug we fixed)
            total_weight = current_alpha + current_beta
            if total_weight > 1.2:
                scale = 1.0 / max(total_weight, 1e-6)  # Fixed potential division issue
                current_alpha *= scale
                current_beta *= scale
        
        student_scheduler.step()
        
        if epoch % 5 == 0:
            log_msg = (f"   CSI Distill Epoch {epoch}: "
                      f"Total={np.mean(epoch_losses['total']):.6f}, "
                      f"KL={np.mean(epoch_losses['kl_distill']):.6f}, "
                      f"Task={np.mean(epoch_losses['task']):.6f}")

            if epoch_losses['feature_align'] and len(epoch_losses['feature_align']) > 0:
                feat_loss = np.mean(epoch_losses['feature_align'])
                log_msg += f", FeatAlign={feat_loss:.6f}"

            if teacher_type == "transformer":
                log_msg += f", T={current_temperature:.1f}"
                if cross_arch_transfer is not None:
                    log_msg += f", Curriculum={0.3:.2f}"  # Show curriculum strength

            log_msg += f", Î±={current_alpha:.3f}, Î²={current_beta:.3f}"
            print(log_msg)
    
    print(f"âœ… CSI-{teacher_type.upper()} â†’ CSI-MAMBA distillation completed!")
    print(f"   Final weights: Î±={current_alpha:.3f}, Î²={current_beta:.3f}")

    if teacher_type == "transformer":
        print(f"   ğŸ”— Enhanced cross-architecture knowledge transfer with curriculum learning completed")
        print(f"   ğŸ§  Advanced techniques: Multi-loss alignment, feature gating, curriculum-based weighting")
        print(f"   ğŸ“Š Temperature progression: {temperature:.1f}â†’{current_temperature:.1f}, Curriculum strength: 0.3")

    return student_model


def run_csi_teacher_ablation_study():
    """
    CSI Teacher Ablation Study comparing different teacher architectures.
    
    Experiments:
    1. CSI-Transformer Teacher â†’ CSI-Mamba Student
    2. CSI-Mamba Teacher â†’ CSI-Mamba Student  
    3. Baseline: CSI-Mamba only (no teacher)
    4. Original: UWB-Transformer Teacher â†’ CSI-Mamba Student (for comparison)
    """
    print("ğŸ”¬ CSI TEACHER ABLATION STUDY")
    print("=" * 80)
    print("ğŸ“Š Comparing teacher architectures with CSI modality:")
    print("   1ï¸âƒ£ CSI-Transformer Teacher â†’ CSI-Mamba Student")
    print("   2ï¸âƒ£ CSI-Mamba Teacher â†’ CSI-Mamba Student")  
    print("   3ï¸âƒ£ Baseline: CSI-Mamba only (no teacher)")
    print("   4ï¸âƒ£ Original: UWB-Transformer Teacher â†’ CSI-Mamba Student")
    print(f"   ğŸ¯ All use {NUM_GAUSSIANS} Gaussian components")
    print("   ğŸ“ˆ FAIR COMPARISON: Identical training parameters + ENTIRE dataset")
    print("   ğŸ”§ FIXED: Removed ALL data limits for comprehensive evaluation")
    
    # Device setup - Force CUDA if available to avoid device mismatch
    if torch.cuda.is_available():
        device = "cuda"
        torch.cuda.empty_cache()  # Clear CUDA cache
        print(f"ğŸ–¥ï¸ Device: {device} (CUDA available)")
        print(f"ğŸ”§ CUDA device count: {torch.cuda.device_count()}")
    else:
        device = "cpu"
        print(f"ğŸ–¥ï¸ Device: {device} (CUDA not available)")
    
    # Don't set default tensor type to avoid data loading conflicts
    # Data loading should handle device placement explicitly
    
    # Setup paths (match truly_fair_comparison.py)
    uwb_data_path = "/media/mohab/Storage HDD/Downloads/uwb2(1)"
    csi_mat_file = "/home/mohab/Desktop/mohawk_final/csi dataset/wificsi1_exp002.mat"
    
    # Create truly fair dataloaders using SAME approach as truly_fair_comparison.py
    print("ğŸ“Š Loading ENTIRE dataset using create_truly_fair_dataloaders...")
    data_loaders = create_truly_fair_dataloaders(
        csi_mat_file=csi_mat_file,
        uwb_data_path=uwb_data_path,
        experiment="002",
            batch_size=32,
            sequence_length=4,
        max_samples=None  # Use ENTIRE CSI dataset (same as truly_fair_comparison.py)
    )
    
    feature_dims = data_loaders['feature_dims']
    print(f"ğŸ“ Model dimensions: CSI={feature_dims['csi']}, UWB={feature_dims['uwb']}")
    
    # CSI config (same as truly_fair_comparison.py)
    csi_config = {
        "CSIRegressionModel": {
            "input": {
                "input_features": feature_dims['csi'],
                "output_features": 2,
                "output_mode": "last",
                "dropout": 0.1
            }
        },
        "UWBMixerModel": {
            "input": {
                "d_model": 80,  # Match truly_fair_comparison.py (was 128)
                "n_layer": 4,
                "final_prenorm": "layer"
            }
        },
        "Block1": {
            "n_layers": 4,
            "BlockType": "modules.phi_block",
            "block_input": {"resid_dropout": 0.1},
            "CoreType": "modules.mixers.discrete_mamba2",
            "core_input": {
                "d_state": 16, "n_v_heads": 8, "n_qk_heads": 8,
                "d_conv": 4, "conv_bias": True, "expand": 2,
                "chunk_size": 64, "activation": "identity", "bias": False
            }
        }
    }
    
    # Training parameters (same for all experiments) - Increased by 10 epochs each
    training_params = {
        'epochs': 30,  # Student epochs (increased from 20 to 30)
        'temperature': 15.0,
        'alpha': 0.2,
        'beta': 0.8,
        'step_size': 0.01,
        'teacher_lr': 1e-3,
        'student_lr': 5e-4
    }
    
    teacher_params = {
        'd_model': 80,  # Match truly_fair_comparison.py (was 128)
        'n_layers': 2, 
        'n_heads': 4
    }
    
    print(f"\nğŸ¯ Training Parameters (ENHANCED with +10 epochs each):")
    print(f"   Baseline: 23 epochs (+10), Teacher: 25-30 epochs (+10), Student: 30 epochs (+10)")
    print(f"   T={training_params['temperature']}, Î±={training_params['alpha']}, Î²={training_params['beta']}")
    print(f"   Teacher LR: {training_params['teacher_lr']:.0e}, Student LR: {training_params['student_lr']:.0e}")
    print(f"   Teacher: d_model={teacher_params['d_model']}, layers={teacher_params['n_layers']}")
    print(f"   ğŸ”§ ENHANCED: Advanced cross-architecture transfer for CSI-Transformer â†’ CSI-Mamba")
    print(f"   ğŸ§  Features: Multi-loss alignment, curriculum learning, feature gating, attention mechanisms")
    print(f"   â±ï¸ EXTENDED: All training phases increased by 10 epochs for better convergence")
    
    # Results storage
    results = {}
    trained_models = {}
    
    # 1ï¸âƒ£ CSI-Transformer Teacher â†’ CSI-Mamba Student
    print(f"\n{'='*60}")
    print("1ï¸âƒ£ CSI-TRANSFORMER â†’ CSI-MAMBA")
    print(f"{'='*60}")
    
    csi_transformer_teacher = CSITransformerTeacher(
        input_features=feature_dims['csi'],
        device=device,
        **teacher_params
    ).to(device)
    
    print(f"ğŸ–¥ï¸ CSI Transformer Teacher moved to {device}")
    
    csi_transformer_student = train_csi_teacher_distilled(
        csi_transformer_teacher, "transformer", csi_config, data_loaders, device, **training_params
    )
    
    trained_models['csi_transformer_student'] = csi_transformer_student
    results['csi_transformer_csi_mamba'] = evaluate_model_performance(
        csi_transformer_student, data_loaders['distilled']['val'], device, "CSI-Transformer â†’ CSI-Mamba", 
        target_scaler=data_loaders['scalers']['target']
    )
    
    # 2ï¸âƒ£ CSI-Mamba Teacher â†’ CSI-Mamba Student
    print(f"\n{'='*60}")
    print("2ï¸âƒ£ CSI-MAMBA â†’ CSI-MAMBA")
    print(f"{'='*60}")
    
    csi_mamba_teacher = CSIMambaTeacher(csi_config, device=device).to(device)
    print(f"ğŸ–¥ï¸ CSI Mamba Teacher moved to {device}")
    
    csi_mamba_student = train_csi_teacher_distilled(
        csi_mamba_teacher, "mamba", csi_config, data_loaders, device, **training_params
    )
    
    trained_models['csi_mamba_student'] = csi_mamba_student
    results['csi_mamba_csi_mamba'] = evaluate_model_performance(
        csi_mamba_student, data_loaders['distilled']['val'], device, "CSI-Mamba â†’ CSI-Mamba",
        target_scaler=data_loaders['scalers']['target']
    )
    
    # 3ï¸âƒ£ Baseline: CSI-Mamba only
    print(f"\n{'='*60}")
    print("3ï¸âƒ£ BASELINE: CSI-MAMBA ONLY")
    print(f"{'='*60}")
    
    baseline_model = train_gmm_baseline(
        csi_config, data_loaders, device, epochs=23  # Increased by 10 epochs
    )
    
    trained_models['baseline'] = baseline_model
    results['baseline_csi_mamba'] = evaluate_model_performance(
        baseline_model, data_loaders['baseline']['val'], device, "Baseline CSI-Mamba",
        target_scaler=data_loaders['scalers']['target']
    )
    
    # Skip UWB teacher comparison if UWB data is not available
    print(f"\n{'='*60}")
    print("4ï¸âƒ£ SKIPPING: UWB-TRANSFORMER â†’ CSI-MAMBA")
    print(f"{'='*60}")
    print("âš ï¸ UWB data not available - focusing on CSI teacher comparison only")
    
    # Create placeholder results for consistency
    results['uwb_transformer_csi_mamba'] = {
        'mae': 999.0,
        'median_ae': 999.0, 
        'r2': -999.0,
        'errors': np.array([999.0]),
        'note': 'UWB data not available'
    }
    
    # ğŸ“Š Compare all results
    print(f"\n{'='*80}")
    print("ğŸ“Š CSI TEACHER ABLATION RESULTS (REAL COORDINATE SPACE)")
    print(f"{'='*80}")
    
    experiments = [
        ('csi_transformer_csi_mamba', '1ï¸âƒ£ CSI-Transformer â†’ CSI-Mamba'),
        ('csi_mamba_csi_mamba', '2ï¸âƒ£ CSI-Mamba â†’ CSI-Mamba'),
        ('baseline_csi_mamba', '3ï¸âƒ£ Baseline CSI-Mamba'),
        ('uwb_transformer_csi_mamba', '4ï¸âƒ£ UWB-Transformer â†’ CSI-Mamba (N/A)')
    ]
    
    # Print comparison table
    print(f"ğŸ¯ All metrics are in REAL coordinate space (meters)")
    print(f"{'Experiment':<35} {'MAE (m)':<12} {'Median AE (m)':<15} {'RÂ²':<10}")
    print("-" * 75)
    
    for key, name in experiments:
        result = results[key]
        mae = result['mae']
        median_ae = result['median_ae'] 
        r2 = result['r2']
        coordinate_space = result.get('coordinate_space', 'unknown')
        space_indicator = " (real)" if coordinate_space == "real_meters" else " (norm)"
        print(f"{name:<35} {mae:<12.4f} {median_ae:<15.4f} {r2:<10.4f}{space_indicator}")
    
    # Analysis
    baseline_mae = results['baseline_csi_mamba']['mae']
    print(f"\nğŸ¯ ABLATION ANALYSIS (REAL COORDINATE SPACE):")
    print(f"ğŸ“ˆ Improvements over Baseline (MAE: {baseline_mae:.4f} meters):")
    
    for key, name in experiments[:-1]:  # Exclude UWB baseline
        if key != 'baseline_csi_mamba':
            improvement = ((baseline_mae - results[key]['mae']) / baseline_mae) * 100
            status = "âœ…" if improvement > 0 else "âŒ"
            print(f"   {status} {name}: {improvement:+.2f}%")
    
    # Skip UWB comparison since UWB data is not available
    print(f"\nğŸ”„ CSI Teachers Comparison (UWB teacher unavailable):")
    print("   ğŸ“Š Focus on CSI teacher architectures:")
    
    csi_experiments = [
        ('csi_transformer_csi_mamba', '1ï¸âƒ£ CSI-Transformer'),
        ('csi_mamba_csi_mamba', '2ï¸âƒ£ CSI-Mamba')
    ]
    
    # Compare CSI teachers to each other
    transformer_mae = results['csi_transformer_csi_mamba']['mae']
    mamba_mae = results['csi_mamba_csi_mamba']['mae']
    
    if transformer_mae < mamba_mae:
        winner = "CSI-Transformer"
        improvement = ((mamba_mae - transformer_mae) / mamba_mae) * 100
    else:
        winner = "CSI-Mamba"
        improvement = ((transformer_mae - mamba_mae) / transformer_mae) * 100
    
    print(f"   ğŸ† Best CSI Teacher: {winner}")
    print(f"   ğŸ“ˆ Performance advantage: {improvement:.2f}%")
    
    # Generate CDF plots
    print(f"\nğŸ“ˆ Generating CDF comparison plots...")
    
    # Extract error data from evaluation results (excluding UWB)
    test_errors = {
        'CSI-Transformer â†’ CSI-Mamba': results['csi_transformer_csi_mamba']['errors'],
        'CSI-Mamba â†’ CSI-Mamba': results['csi_mamba_csi_mamba']['errors'],
        'Baseline CSI-Mamba': results['baseline_csi_mamba']['errors']
    }
    
    # Plot CDF comparison
    plot_error_cdf_comparison(test_errors, 'csi_teacher_ablation_cdf.png')
    
    # Save results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"csi_teacher_ablation_results_{timestamp}.json"
    
    save_results = {
        'timestamp': timestamp,
        'experiment_type': 'csi_teacher_ablation',
        'parameters': {**training_params, **teacher_params},
        'experiments': dict(experiments),
        'results': results,
        'analysis': {
            'baseline_mae': baseline_mae,
            'improvements_over_baseline': {
                key: ((baseline_mae - results[key]['mae']) / baseline_mae) * 100
                for key, _ in experiments if key != 'baseline_csi_mamba' and key != 'uwb_transformer_csi_mamba'
            },
            'csi_teacher_comparison': {
                'transformer_mae': results['csi_transformer_csi_mamba']['mae'],
                'mamba_mae': results['csi_mamba_csi_mamba']['mae'],
                'baseline_mae': baseline_mae
            },
            'coordinate_space': 'real_meters'
        }
    }
    
    with open(results_file, 'w') as f:
        json.dump(save_results, f, indent=2)
    
    print(f"\nğŸ’¾ Results saved to: {results_file}")
    print(f"ğŸ“ˆ CDF plot saved as: csi_teacher_ablation_cdf.png")
    print(f"ğŸ¯ NOTE: All metrics are in REAL coordinate space (meters)")
    print(f"ğŸ“Š Coordinate space: X=[0,{COORD_MAX_X}]m, Y=[0,{COORD_MAX_Y}]m")
    print(f"ğŸ”§ ENHANCED: Advanced cross-architecture transfer for CSI-Transformer â†’ CSI-Mamba")
    print(f"ğŸ§  Features: Multi-loss alignment, curriculum learning, feature gating, attention mechanisms")
    
    return results


if __name__ == "__main__":
    print("ğŸš€ ENHANCED CSI TEACHER ABLATION STUDY (+10 EPOCHS)")
    print("=" * 80)
    print("ğŸ¯ Advanced cross-architecture transfer study:")
    print("   â€¢ CSI-Transformer â†’ CSI-Mamba with enhanced feature alignment")
    print("   â€¢ CSI-Mamba â†’ CSI-Mamba (same architecture baseline)")
    print("   â€¢ Multi-loss alignment, curriculum learning, feature gating")
    print("   â€¢ Extended training: +10 epochs for all phases (baseline, teacher, student)")
    print("   â€¢ Comparison with UWB-Transformer baseline")
    print()
    
    results = run_csi_teacher_ablation_study()
    
    print("\nğŸ‰ CSI teacher ablation study completed!")
    print("ğŸ“Š Check results file and CDF plot for detailed analysis")
    print("ğŸ¯ All metrics calculated in REAL coordinate space (meters)")
    print("ğŸ”§ ENHANCED with advanced cross-architecture transfer for CSI-Transformer â†’ CSI-Mamba")
    print("ğŸ§  Features: Multi-loss alignment, curriculum learning, feature gating, attention mechanisms")
